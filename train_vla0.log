nohup: ignoring input
DATALOADER:
  ROBOVERSE:
    cfg_opts: IMAGE.crop_img:0.875:IMAGE.img_size:224:IMAGE.cam_list:('3p1','3p2')
    cfg_path: libs/RoboVerse/roboverse/configs/img_libero_aug.yaml
  batch_size: 16
  num_workers: 4
EXP:
  AMP: True
  DATASET: roboverse
  EXP_ID: vla0_qwen3b_fullft_bs8_lr5e-6_ep24
  LOSS:
    
  LR_SCHED: none
  MODEL: qwen
  OPTIMIZER: adamw
  SEED: 0
EXP_EXTRA:
  no_test: True
  no_track: True
  no_val: True
  save_ckp: 1
  save_last_ckpt: True
  test_eval_freq: 1
  val_eval_freq: 1
LR_SCHED:
  lr_clip: 1e-08
  lr_decay_factor: 0.5
  lr_patience: 4
MODEL:
  QWEN:
    action_mask_aug_per: 0.4
    action_type: original
    add_vision_id: True
    attention_dropout: 0.0
    history: 1
    horizon: 8
    lora_config: default
    lora_rank: 8
    num_bins_actions: 1000
    num_cam: 2
    original_action_dim: 7
    qwen_model_id: Qwen/Qwen2.5-VL-3B-Instruct
    rgb_img_size: (224, 224)
    rgb_input: True
    tiled_rgb_imgs: True
    use_flash_attention_2: False
    use_lora: False
    use_qlora: False
TRAIN:
  clip_grad_norm: 0.0
  l2: 1e-10
  lr: 5e-06
  num_epochs: 2
WARNING: split is ignored for roboverse dataset.
LeRobot and RoboVerse Camera Mapping: ['image', 'wrist_image'] -> ['3p1', '3p2']
Delta Timestamps: {'state': [0.0], 'actions': [-0.1, 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]}
Stats: {'out_ori_act': {'max': array([0.9375    , 0.9375    , 0.9375    , 0.35571429, 0.375     ,
       0.375     , 1.        ]), 'min': array([-0.9375    , -0.9375    , -0.9375    , -0.25821429, -0.375     ,
       -0.36750001, -1.        ])}}
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.06it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.03it/s]
The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.
WARNING: Using hardcoded dataset stats for DP3. This should be replaced with loading from a file.
WARNING: split is ignored for roboverse dataset.
LeRobot and RoboVerse Camera Mapping: ['image', 'wrist_image'] -> ['3p1', '3p2']
Delta Timestamps: {'state': [0.0], 'actions': [-0.1, 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]}
Stats: {'out_ori_act': {'max': array([0.9375    , 0.9375    , 0.9375    , 0.35571429, 0.375     ,
       0.375     , 1.        ]), 'min': array([-0.9375    , -0.9375    , -0.9375    , -0.25821429, -0.375     ,
       -0.36750001, -1.        ])}}
QwenActor(
  (model): Qwen2_5_VLForConditionalGeneration(
    (model): Qwen2_5_VLModel(
      (visual): Qwen2_5_VisionTransformerPretrainedModel(
        (patch_embed): Qwen2_5_VisionPatchEmbed(
          (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)
        )
        (rotary_pos_emb): Qwen2_5_VisionRotaryEmbedding()
        (blocks): ModuleList(
          (0-31): 32 x Qwen2_5_VLVisionBlock(
            (norm1): Qwen2RMSNorm((1280,), eps=1e-06)
            (norm2): Qwen2RMSNorm((1280,), eps=1e-06)
            (attn): Qwen2_5_VLVisionAttention(
              (qkv): Linear(in_features=1280, out_features=3840, bias=True)
              (proj): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (mlp): Qwen2_5_VLMLP(
              (gate_proj): Linear(in_features=1280, out_features=3420, bias=True)
              (up_proj): Linear(in_features=1280, out_features=3420, bias=True)
              (down_proj): Linear(in_features=3420, out_features=1280, bias=True)
              (act_fn): SiLUActivation()
            )
          )
        )
        (merger): Qwen2_5_VLPatchMerger(
          (ln_q): Qwen2RMSNorm((1280,), eps=1e-06)
          (mlp): Sequential(
            (0): Linear(in_features=5120, out_features=5120, bias=True)
            (1): GELU(approximate='none')
            (2): Linear(in_features=5120, out_features=2048, bias=True)
          )
        )
      )
      (language_model): Qwen2_5_VLTextModel(
        (embed_tokens): Embedding(151936, 2048)
        (layers): ModuleList(
          (0-35): 36 x Qwen2_5_VLDecoderLayer(
            (self_attn): Qwen2_5_VLAttention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=256, bias=True)
              (v_proj): Linear(in_features=2048, out_features=256, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2_5_VLRotaryEmbedding()
            )
            (mlp): Qwen2MLP(
              (gate_proj): Linear(in_features=2048, out_features=11008, bias=False)
              (up_proj): Linear(in_features=2048, out_features=11008, bias=False)
              (down_proj): Linear(in_features=11008, out_features=2048, bias=False)
              (act_fn): SiLUActivation()
            )
            (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)
            (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)
          )
        )
        (norm): Qwen2RMSNorm((2048,), eps=1e-06)
        (rotary_emb): Qwen2_5_VLRotaryEmbedding()
      )
    )
    (lm_head): Linear(in_features=2048, out_features=151936, bias=False)
  )
  (loss_fn): CrossEntropyLoss()
)
==================================================
Model Statistics:
Total parameters: 3,754,622,976
Trainable parameters: 3,754,622,976
Non-trainable parameters: 0
==================================================
[rank0]:[W1203 20:51:45.180678028 ProcessGroupNCCL.cpp:5072] Guessing device ID based on global rank. This can cause a hang if rank to GPU mapping is heterogeneous. You can specify device_id in init_process_group()
Log directory: ./runs/vla0_qwen3b_fullft_bs8_lr5e-6_ep24
Training for epoch 0 / 2
Not tracking performance
[epoch 0/1] iter 1/17091  loss 1.6788  avg_loss 1.6788  it/s 0.05  t_fwd 3.512s  t_bwd 3.473s  t_data 14.799s
[epoch 0/1] iter 20/17091  loss 1.1767  avg_loss 1.4348  it/s 0.14  t_fwd 3.044s  t_bwd 3.278s  t_data 0.756s
[epoch 0/1] iter 40/17091  loss 1.1517  avg_loss 1.3222  it/s 0.15  t_fwd 3.073s  t_bwd 3.281s  t_data 0.386s
[epoch 0/1] iter 60/17091  loss 1.0217  avg_loss 1.2421  it/s 0.15  t_fwd 3.074s  t_bwd 3.284s  t_data 0.263s
[epoch 0/1] iter 80/17091  loss 0.9897  avg_loss 1.1827  it/s 0.15  t_fwd 3.080s  t_bwd 3.283s  t_data 0.202s
[epoch 0/1] iter 100/17091  loss 0.9376  avg_loss 1.1431  it/s 0.15  t_fwd 3.083s  t_bwd 3.289s  t_data 0.165s
